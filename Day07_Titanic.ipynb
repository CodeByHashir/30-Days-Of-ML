{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 7: Titanic Survival Prediction - End-to-End ML Project\n",
        "\n",
        "**Welcome to your first complete machine learning project!** Today we'll apply everything you've learned in the past 6 days to solve a real-world problem: predicting passenger survival on the Titanic. This is a classic binary classification problem that will help you understand the complete ML workflow.\n",
        "\n",
        "---\n",
        "\n",
        "**Goal:** Build a complete ML pipeline to predict Titanic passenger survival using real data and multiple algorithms.\n",
        "\n",
        "**Skills You'll Practice:**\n",
        "- Exploratory Data Analysis (EDA)\n",
        "- Data preprocessing and feature engineering\n",
        "- Multiple ML algorithms (Logistic Regression, Random Forest, etc.)\n",
        "- Model evaluation and comparison\n",
        "- End-to-end project workflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. Project Overview & Setup\n",
        "\n",
        "### The Titanic Challenge\n",
        "On April 15, 1912, the RMS Titanic sank after colliding with an iceberg. This tragedy resulted in the deaths of over 1,500 passengers and crew. Using machine learning, we can analyze patterns in the data to predict which passengers were more likely to survive.\n",
        "\n",
        "### What We'll Build\n",
        "A binary classifier that predicts passenger survival (0 = died, 1 = survived) based on features like age, ticket class, gender, and fare paid.\n",
        "\n",
        "### Key ML Concepts We'll Practice\n",
        "- **Binary Classification**: Predicting one of two outcomes (survived/died)\n",
        "- **Feature Engineering**: Creating new features from existing ones\n",
        "- **Model Comparison**: Testing multiple algorithms to find the best performer\n",
        "- **Cross-Validation**: Ensuring our model generalizes well to new data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import essential libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(\"Ready to start the Titanic project!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Load and Initial Exploration\n",
        "\n",
        "**Task:** Load the Titanic dataset and get your first look at the data.\n",
        "\n",
        "**Questions to think about:**\n",
        "- How many passengers are in the dataset?\n",
        "- What features do we have available?\n",
        "- Are there any missing values?\n",
        "- What does the target variable (Survived) look like?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load the Titanic dataset\n",
        "# Hint: Use pd.read_csv() to load 'titanic.csv'\n",
        "\n",
        "# Your code here:\n",
        "df = \n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumn names:\")\n",
        "print(df.columns.tolist())\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Get basic information about the dataset\n",
        "# Check data types, missing values, and basic statistics\n",
        "# Hint: Use df.info(), df.isnull().sum(), and df['Survived'].value_counts()\n",
        "\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nTarget Variable Distribution:\")\n",
        "print(df['Survived'].value_counts())\n",
        "print(f\"\\nSurvival Rate: {df['Survived'].mean():.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflection Questions:**\n",
        "1. What percentage of passengers survived?\n",
        "2. Which features have missing values?\n",
        "3. What data types do we have? (numeric, categorical, text)\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Exploratory Data Analysis (EDA)\n",
        "\n",
        "Now let's dive deeper into the data to understand patterns and relationships that might help predict survival.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Survival by Key Features\n",
        "\n",
        "**Task:** Analyze how different features relate to survival rates.\n",
        "\n",
        "**Key questions:**\n",
        "- Did gender affect survival chances?\n",
        "- How did ticket class (Pclass) influence survival?\n",
        "- What about age groups?\n",
        "- Did passengers with family members have better survival rates?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create visualizations to explore survival patterns\n",
        "# Create a 2x2 subplot layout to compare different features\n",
        "\n",
        "# 1. Survival by Gender\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "# TODO: Create a countplot showing survival by gender\n",
        "# Hint: Use sns.countplot with data=df, x='Sex', hue='Survived'\n",
        "# Your code here:\n",
        "\n",
        "plt.title('Survival Count by Gender')\n",
        "\n",
        "# 2. Survival by Passenger Class\n",
        "plt.subplot(2, 2, 2)\n",
        "# TODO: Create a countplot showing survival by passenger class\n",
        "# Hint: Use sns.countplot with data=df, x='Pclass', hue='Survived'\n",
        "# Your code here:\n",
        "\n",
        "plt.title('Survival Count by Passenger Class')\n",
        "\n",
        "# 3. Age distribution by survival\n",
        "plt.subplot(2, 2, 3)\n",
        "# TODO: Create a histogram showing age distribution by survival\n",
        "# Hint: Use sns.histplot with data=df, x='Age', hue='Survived', alpha=0.7\n",
        "# Your code here:\n",
        "\n",
        "plt.title('Age Distribution by Survival')\n",
        "\n",
        "# 4. Fare distribution by survival\n",
        "plt.subplot(2, 2, 4)\n",
        "# TODO: Create a histogram showing fare distribution by survival\n",
        "# Hint: Use sns.histplot with data=df, x='Fare', hue='Survived', alpha=0.7\n",
        "# Your code here:\n",
        "\n",
        "plt.title('Fare Distribution by Survival')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Calculate survival rates by different features\n",
        "# Hint: Use df.groupby() to calculate mean survival rates for different features\n",
        "\n",
        "print(\"Survival Rates by Feature:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# TODO: Calculate survival rate by gender\n",
        "# Hint: Use df.groupby('Sex')['Survived'].mean()\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# TODO: Calculate survival rate by passenger class\n",
        "# Hint: Use df.groupby('Pclass')['Survived'].mean()\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# TODO: Calculate survival rate by embarkation port\n",
        "# Hint: Use df.groupby('Embarked')['Survived'].mean()\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "print(f\"\\nBy Gender:\")\n",
        "print(\"Your results here...\")\n",
        "\n",
        "print(f\"\\nBy Passenger Class:\")\n",
        "print(\"Your results here...\")\n",
        "\n",
        "print(f\"\\nBy Embarkation Port:\")\n",
        "print(\"Your results here...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Feature Engineering\n",
        "\n",
        "**Task:** Create new features that might improve our model's performance.\n",
        "\n",
        "**Ideas to explore:**\n",
        "- Family size (SibSp + Parch + 1)\n",
        "- Age groups (child, adult, senior)\n",
        "- Title extraction from names (Mr., Mrs., Miss, etc.)\n",
        "- Fare per person (Fare / Family Size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create new features to improve model performance\n",
        "\n",
        "# 1. Family Size\n",
        "# TODO: Create a FamilySize feature by adding SibSp + Parch + 1\n",
        "# Hint: df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# 2. Is Alone (no family members)\n",
        "# TODO: Create an IsAlone feature (1 if FamilySize == 1, 0 otherwise)\n",
        "# Hint: df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# 3. Age Groups\n",
        "# TODO: Create age groups using pd.cut()\n",
        "# Hint: Use bins=[0, 12, 18, 35, 60, 100] and labels=['Child', 'Teen', 'Young Adult', 'Adult', 'Senior']\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# 4. Extract Title from Name\n",
        "# TODO: Extract titles from names using string methods\n",
        "# Hint: Use df['Name'].str.extract() with regex pattern\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# 5. Fare per Person\n",
        "# TODO: Create FarePerPerson by dividing Fare by FamilySize\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "print(\"New features created!\")\n",
        "print(f\"\\nFamily Size distribution:\")\n",
        "print(\"Your results here...\")\n",
        "\n",
        "print(f\"\\nTitle distribution:\")\n",
        "print(\"Your results here...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Visualize new features to understand their relationship with survival\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Family Size vs Survival\n",
        "plt.subplot(1, 3, 1)\n",
        "# TODO: Create a barplot showing survival rate by family size\n",
        "# Hint: Use sns.barplot(data=df, x='FamilySize', y='Survived')\n",
        "# Your code here:\n",
        "\n",
        "plt.title('Survival Rate by Family Size')\n",
        "plt.ylabel('Survival Rate')\n",
        "\n",
        "# Age Group vs Survival\n",
        "plt.subplot(1, 3, 2)\n",
        "# TODO: Create a barplot showing survival rate by age group\n",
        "# Hint: Use sns.barplot(data=df, x='AgeGroup', y='Survived')\n",
        "# Your code here:\n",
        "\n",
        "plt.title('Survival Rate by Age Group')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Survival Rate')\n",
        "\n",
        "# Title vs Survival (top 5 titles)\n",
        "plt.subplot(1, 3, 3)\n",
        "# TODO: Filter to top 5 titles and create barplot\n",
        "# Hint: First get top_titles = df['Title'].value_counts().head(5).index\n",
        "# Then filter: title_data = df[df['Title'].isin(top_titles)]\n",
        "# Finally: sns.barplot(data=title_data, x='Title', y='Survived')\n",
        "# Your code here:\n",
        "\n",
        "plt.title('Survival Rate by Title (Top 5)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Survival Rate')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflection Questions:**\n",
        "1. Which features show the strongest relationship with survival?\n",
        "2. What patterns did you discover that might help predict survival?\n",
        "3. Are there any surprising findings?\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Data Preprocessing\n",
        "\n",
        "Now let's prepare our data for machine learning by handling missing values, encoding categorical variables, and scaling features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 4: Handle Missing Values and Encode Categorical Variables\n",
        "\n",
        "**Task:** Clean the data for machine learning.\n",
        "\n",
        "**Steps:**\n",
        "1. Handle missing values in Age, Cabin, and Embarked\n",
        "2. Encode categorical variables (Sex, Embarked, Title)\n",
        "3. Select relevant features for modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Handle missing values strategically\n",
        "# Think about which method makes sense for each feature\n",
        "\n",
        "# 1. Age - Fill with median age grouped by Pclass and Sex\n",
        "# TODO: Use groupby and transform to fill Age missing values\n",
        "# Hint: df.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# 2. Embarked - Fill with mode (most common value)\n",
        "# TODO: Fill missing Embarked values with the most frequent value\n",
        "# Hint: df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# 3. Fare - Fill with median fare by Pclass\n",
        "# TODO: Use groupby to fill missing Fare values\n",
        "# Hint: Similar to Age but group by 'Pclass' only\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# 4. Cabin - Create a binary feature indicating if passenger had a cabin\n",
        "# TODO: Create HasCabin feature (1 if cabin exists, 0 if not)\n",
        "# Hint: df['Cabin'].notna().astype(int)\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "print(\"Missing values after preprocessing:\")\n",
        "print(\"Your results here...\")\n",
        "\n",
        "print(f\"\\nAge statistics after filling:\")\n",
        "print(\"Your results here...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Encode categorical variables for machine learning\n",
        "\n",
        "# Label encoding for binary variables (Sex)\n",
        "# TODO: Use LabelEncoder to encode Sex column\n",
        "# Hint: le_sex = LabelEncoder() then df['Sex_encoded'] = le_sex.fit_transform(df['Sex'])\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# One-hot encoding for multi-class variables\n",
        "# TODO: Use pd.get_dummies for Embarked and Title columns\n",
        "# Hint: df = pd.get_dummies(df, columns=['Embarked', 'Title'], prefix=['Emb', 'Title'])\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "print(\"Categorical variables encoded!\")\n",
        "print(f\"\\nSex mapping:\")\n",
        "print(\"Your results here...\")\n",
        "\n",
        "print(f\"\\nNew columns created:\")\n",
        "print(\"Your results here...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Select features for modeling\n",
        "# Choose which features to use in your model\n",
        "\n",
        "# TODO: Define your feature columns list\n",
        "# Include: 'Pclass', 'Sex_encoded', 'Age', 'SibSp', 'Parch', 'Fare', \n",
        "#          'FamilySize', 'IsAlone', 'HasCabin', 'FarePerPerson'\n",
        "# Plus any columns that start with 'Emb_' or 'Title_'\n",
        "# Hint: Use list comprehension to get dummy columns\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# TODO: Create feature matrix X and target vector y\n",
        "# Hint: X = df[feature_columns], y = df['Survived']\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Target vector shape: {y.shape}\")\n",
        "print(f\"\\nSelected features:\")\n",
        "print(\"Your feature list here...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Model Building and Evaluation\n",
        "\n",
        "Time to build and compare multiple machine learning models!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 5: Train-Test Split and Model Training\n",
        "\n",
        "**Task:** Split the data and train multiple models to compare their performance.\n",
        "\n",
        "**Models to try:**\n",
        "- Logistic Regression\n",
        "- Random Forest Classifier\n",
        "- Support Vector Machine (bonus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Split the data into training and testing sets\n",
        "# Hint: Use train_test_split with test_size=0.2, random_state=42, stratify=y\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# TODO: Scale the features for models that need it (like Logistic Regression)\n",
        "# Hint: Use StandardScaler() to fit on training data and transform both sets\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n",
        "print(f\"\\nTraining set survival rate: {y_train.mean():.2%}\")\n",
        "print(f\"Test set survival rate: {y_test.mean():.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Train and evaluate multiple models\n",
        "\n",
        "# TODO: Create a dictionary of models to compare\n",
        "# Include LogisticRegression and RandomForestClassifier\n",
        "# Hint: models = {'Logistic Regression': LogisticRegression(random_state=42), ...}\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# TODO: Initialize results dictionary to store model performance\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    # TODO: Train the model\n",
        "    # Hint: Use scaled data for Logistic Regression, original data for Random Forest\n",
        "    # Your code here:\n",
        "    \n",
        "    \n",
        "    # TODO: Make predictions on test set\n",
        "    # Your code here:\n",
        "    \n",
        "    \n",
        "    # TODO: Calculate accuracy score\n",
        "    # Hint: Use accuracy_score(y_test, y_pred)\n",
        "    # Your code here:\n",
        "    \n",
        "    \n",
        "    # TODO: Perform cross-validation\n",
        "    # Hint: Use cross_val_score with cv=5\n",
        "    # Your code here:\n",
        "    \n",
        "    \n",
        "    # TODO: Store results in dictionary\n",
        "    # Your code here:\n",
        "    \n",
        "    \n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"CV Mean: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "    \n",
        "    # TODO: Print classification report\n",
        "    # Hint: Use classification_report(y_test, y_pred)\n",
        "    # Your code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Compare model performance and find the best one\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# TODO: Loop through results and print performance metrics\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# TODO: Find the best model based on accuracy\n",
        "# Hint: Use max() with a key function\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "print(f\"\\nBest Model: {best_model} with {results[best_model]['accuracy']:.4f} accuracy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 6: Feature Importance Analysis\n",
        "\n",
        "**Task:** Understand which features are most important for predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Analyze feature importance (for Random Forest)\n",
        "\n",
        "# TODO: Check if Random Forest model exists and analyze feature importance\n",
        "# Hint: Use if 'Random Forest' in models:\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "    # TODO: Create a DataFrame with feature names and importance scores\n",
        "    # Hint: Use pd.DataFrame with 'feature' and 'importance' columns\n",
        "    # Your code here:\n",
        "    \n",
        "    \n",
        "    # TODO: Create a barplot of top 10 most important features\n",
        "    # Hint: Use sns.barplot with the top 10 features\n",
        "    # Your code here:\n",
        "    \n",
        "    \n",
        "    print(\"Top 10 Most Important Features:\")\n",
        "    # TODO: Print the top 10 features and their importance scores\n",
        "    # Your code here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 7: Model Interpretation\n",
        "\n",
        "**Task:** Create visualizations to understand model predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create confusion matrix for best model\n",
        "\n",
        "# TODO: Get predictions from the best model\n",
        "# Hint: Use results[best_model]['predictions']\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# TODO: Create confusion matrix visualization\n",
        "# Hint: Use confusion_matrix() and sns.heatmap()\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "# TODO: Print confusion matrix details\n",
        "# Hint: Use cm.ravel() to get tn, fp, fn, tp\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "print(f\"\\nConfusion Matrix Details:\")\n",
        "print(\"Your results here...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Project Summary and Insights\n",
        "\n",
        "### Exercise 8: Key Insights and Learnings\n",
        "\n",
        "**Task:** Reflect on what you've learned and the insights gained.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key Findings from Our Analysis:\n",
        "\n",
        "1. **Gender was the strongest predictor**: Women had a much higher survival rate (~74%) compared to men (~19%)\n",
        "2. **Passenger class mattered**: First-class passengers had better survival rates than third-class passengers\n",
        "3. **Age played a role**: Children had higher survival rates, possibly due to \"women and children first\" evacuation policy\n",
        "4. **Family size had mixed effects**: Very large families (7+ members) had lower survival rates\n",
        "\n",
        "### Model Performance:\n",
        "- Our models achieved accuracy in the range of 80-85%\n",
        "- Random Forest typically performs well on this dataset\n",
        "- Feature engineering (creating new features) often improves model performance\n",
        "\n",
        "### What This Teaches Us:\n",
        "- **Domain knowledge matters**: Understanding the historical context (women and children first) helps interpret results\n",
        "- **Feature engineering is crucial**: Creating meaningful features can significantly improve model performance\n",
        "- **Multiple models should be compared**: Different algorithms may perform better on different types of data\n",
        "- **Model interpretation is important**: Understanding which features matter helps build trust in the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge Questions (Optional):\n",
        "\n",
        "Try these extensions to deepen your understanding:\n",
        "\n",
        "1. **Feature Engineering Challenge**: Create more sophisticated features like:\n",
        "   - Age categories based on survival patterns you observed\n",
        "   - Fare categories (low, medium, high)\n",
        "   - Family size categories\n",
        "\n",
        "2. **Model Tuning**: Try hyperparameter tuning for your best model:\n",
        "   ```python\n",
        "   from sklearn.model_selection import GridSearchCV\n",
        "   # Tune Random Forest parameters like n_estimators, max_depth, etc.\n",
        "   ```\n",
        "\n",
        "3. **Additional Models**: Try other algorithms:\n",
        "   - Support Vector Machine\n",
        "   - Gradient Boosting\n",
        "   - Naive Bayes\n",
        "\n",
        "4. **Advanced Evaluation**: Implement more sophisticated evaluation:\n",
        "   - ROC curves and AUC scores\n",
        "   - Precision-Recall curves\n",
        "   - Learning curves\n",
        "\n",
        "5. **Business Insights**: Think about how this model could be used:\n",
        "   - What would you tell a cruise line about passenger safety?\n",
        "   - How might this analysis inform emergency procedures?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. Next Steps and Further Learning\n",
        "\n",
        "### Congratulations!\n",
        "You've completed your first end-to-end machine learning project! You've learned how to:\n",
        "- Perform exploratory data analysis\n",
        "- Engineer features to improve model performance\n",
        "- Train and evaluate multiple machine learning models\n",
        "- Interpret results and draw meaningful insights\n",
        "\n",
        "### Recommended Next Steps:\n",
        "\n",
        "1. **Kaggle Competitions**: \n",
        "   - Submit your predictions to the actual Titanic competition\n",
        "   - Explore other beginner-friendly competitions\n",
        "   - Learn from top solutions and discussions\n",
        "\n",
        "2. **Advanced Techniques to Explore**:\n",
        "   - **Ensemble Methods**: Combine multiple models for better predictions\n",
        "   - **Cross-Validation**: Use k-fold cross-validation for more robust evaluation\n",
        "   - **Feature Selection**: Learn techniques to select the most important features\n",
        "   - **Hyperparameter Tuning**: Optimize model parameters for better performance\n",
        "\n",
        "3. **Related Datasets to Practice On**:\n",
        "   - **House Prices**: Predict house prices (regression problem)\n",
        "   - **Customer Churn**: Predict which customers will leave (classification)\n",
        "   - **Spam Detection**: Classify emails as spam or not spam\n",
        "   - **Loan Default**: Predict loan default risk\n",
        "\n",
        "4. **Skills to Develop Next**:\n",
        "   - **Model Deployment**: Learn to deploy models as web applications\n",
        "   - **MLOps**: Learn about model versioning and monitoring\n",
        "   - **Deep Learning**: Explore neural networks for more complex problems\n",
        "   - **Time Series**: Learn to handle temporal data\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "- **Data understanding is crucial**: Spend time exploring your data before modeling\n",
        "- **Feature engineering matters**: Often more important than choosing the \"best\" algorithm\n",
        "- **Domain knowledge helps**: Understanding the problem context improves your analysis\n",
        "- **Multiple models should be compared**: Don't rely on just one algorithm\n",
        "- **Interpretability is important**: Being able to explain your model builds trust\n",
        "\n",
        "### Useful Resources:\n",
        "\n",
        "- **Kaggle Learn**: Free micro-courses on data science and machine learning\n",
        "- **Scikit-learn Documentation**: Comprehensive guide to ML algorithms\n",
        "- **Towards Data Science**: Medium publication with practical ML articles\n",
        "- **Machine Learning Mastery**: Jason Brownlee's excellent ML tutorials\n",
        "\n",
        "**Keep practicing and building projects!** The more you work with real data and solve real problems, the better you'll become at machine learning.\n",
        "\n",
        "---\n",
        "## üì´ Let's Connect\n",
        "- üíº **LinkedIn:** [hashirahmed07](https://www.linkedin.com/in/hashirahmed07/)\n",
        "- üìß **Email:** [Hashirahmad330@gmail.com](mailto:Hashirahmad330@gmail.com)\n",
        "- üêô **GitHub:** [CodeByHashir](https://github.com/CodeByHashir)\n",
        "\n",
        "---\n",
        "\n",
        "*Happy Learning!*\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
