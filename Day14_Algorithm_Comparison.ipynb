{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 14: Algorithm Comparison Mini-Project\n",
        "\n",
        "**Week 2 - Comprehensive ML Model Comparison Practice Template**\n",
        "\n",
        "Welcome to Day 14 of your ML journey! Today we tackle one of the most critical decisions in machine learning: **Algorithm Selection**. Choosing the right algorithm can make the difference between a mediocre model and an exceptional one. you'll perform comprehensive model comparison, performance evaluation across multiple metrics, cross-validation techniques, and systematic algorithm selection strategies.\n",
        "\n",
        "---\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this project, you will be able to:\n",
        "\n",
        "1. **Apply multiple ML algorithms** to the same dataset\n",
        "2. **Compare model performance** using various evaluation metrics  \n",
        "3. **Understand algorithm strengths and weaknesses** in practice\n",
        "4. **Make informed decisions** about model selection\n",
        "5. **Create visualizations** to communicate results effectively\n",
        "\n",
        "### Key ML Concepts Practiced\n",
        "\n",
        "- Complete ML Pipeline: From raw data to model evaluation\n",
        "- Data Preprocessing: Handling missing values, encoding, scaling\n",
        "- Model Building: Implementing 9 different algorithms\n",
        "- Model Evaluation: Accuracy, precision, recall, F1-Score, ROC-AUC\n",
        "- Cross-Validation: Ensuring robust model evaluation\n",
        "- Visualization: Creating comparison charts and performance plots\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Overview\n",
        "\n",
        "### The Challenge\n",
        "\n",
        "In this project, you will work with a **Heart Disease Prediction** dataset to:\n",
        "- Compare 9 different ML algorithms\n",
        "- Evaluate their performance comprehensively\n",
        "- Identify the best model for this medical diagnosis problem\n",
        "\n",
        "### Why This Matters\n",
        "\n",
        "In real-world ML projects:\n",
        "- **No single algorithm works best for all problems**\n",
        "- **Data characteristics matter**: Dataset size, features, noise, class balance\n",
        "- **Different metrics reveal different insights**: Accuracy alone is not enough\n",
        "- **Computational cost vs. performance**: Sometimes simpler models are better\n",
        "\n",
        "### Algorithms You Will Compare\n",
        "\n",
        "| Algorithm | Type | Best Use Cases |\n",
        "|-----------|------|----------------|\n",
        "| Logistic Regression | Linear | Baseline, interpretability |\n",
        "| Decision Tree | Tree-based | Non-linear patterns, interpretability |\n",
        "| Random Forest | Ensemble | High accuracy, feature importance |\n",
        "| Gradient Boosting | Ensemble | Competition-winning performance |\n",
        "| XGBoost | Ensemble (Advanced) | State-of-the-art performance |\n",
        "| LightGBM | Ensemble (Advanced) | Large datasets, speed |\n",
        "| Support Vector Machine | Kernel-based | High-dimensional data |\n",
        "| k-Nearest Neighbors | Instance-based | Small datasets, non-parametric |\n",
        "| Naive Bayes | Probabilistic | Fast training, works with small data |\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Setup and Data Loading\n",
        "\n",
        "Let's start by importing all necessary libraries and loading our dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Import all required libraries\n",
        "# Data manipulation: numpy, pandas\n",
        "# Visualization: matplotlib, seaborn  \n",
        "# Configure warnings and matplotlib inline\n",
        "# Preprocessing: train_test_split, cross_val_score, StratifiedKFold, StandardScaler, SimpleImputer\n",
        "# Models: LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier, \n",
        "#         SVC, KNeighborsClassifier, GaussianNB, XGBClassifier, LGBMClassifier\n",
        "# Metrics: accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
        "#          confusion_matrix, classification_report, roc_curve\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading the Dataset\n",
        "\n",
        "**Dataset**: Heart Disease UCI  \n",
        "**URL**: https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data  \n",
        "**Target**: Binary classification (0 = No disease, 1 = Disease)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of       age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
              "1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
              "2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
              "3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
              "4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
              "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
              "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
              "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
              "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
              "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
              "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
              "\n",
              "     slope   ca  thal  target  \n",
              "0      3.0  0.0   6.0       0  \n",
              "1      2.0  3.0   3.0       2  \n",
              "2      2.0  2.0   7.0       1  \n",
              "3      3.0  0.0   3.0       0  \n",
              "4      1.0  0.0   3.0       0  \n",
              "..     ...  ...   ...     ...  \n",
              "298    2.0  0.0   7.0       1  \n",
              "299    2.0  2.0   7.0       2  \n",
              "300    2.0  1.0   7.0       3  \n",
              "301    2.0  1.0   3.0       1  \n",
              "302    1.0  NaN   3.0       0  \n",
              "\n",
              "[303 rows x 14 columns]>"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
        "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
        "                'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
        "\n",
        "# TODO: Load dataset with pd.read_csv(url, names=column_names, na_values='?')\n",
        "# TODO: Convert target to binary: (df['target'] > 0).astype(int)\n",
        "# TODO: Display shape and first few rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Display dataset info using df.info()\n",
        "# TODO: Display statistical summary using df.describe()\n",
        "# TODO: Check missing values using df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflection Question 1:** What do you notice about missing values? How will this affect model building?\n",
        "\n",
        "*Write your observations here:*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 2: Exploratory Data Analysis\n",
        "\n",
        "Before building models, analyze the data to understand patterns and relationships.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Visualize target distribution with bar chart and pie chart\n",
        "# TODO: Calculate class distribution percentages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Plot distributions of numerical features\n",
        "# Suggested: age, trestbps, chol, thalach, oldpeak\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create correlation heatmap\n",
        "# TODO: Find and display features most correlated with target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflection Question 2:** Which features are most strongly correlated with heart disease? Any multicollinearity issues?\n",
        "\n",
        "*Write your insights here:*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 3: Data Preprocessing\n",
        "\n",
        "Prepare the data for modeling by handling missing values, splitting data, and scaling features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Handle missing values using SimpleImputer with median strategy\n",
        "# TODO: Verify no missing values remain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Separate features (X) and target (y)\n",
        "# TODO: Perform stratified train-test split (test_size=0.2, random_state=42)\n",
        "# TODO: Display split sizes and class distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Scale features using StandardScaler\n",
        "# Important: Fit only on training data to prevent data leakage\n",
        "# TODO: Verify scaling (mean ~0, std ~1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflection Question 3:** Why fit scaler only on training data? Explain data leakage.\n",
        "\n",
        "*Explain the concept:*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 4: Model Training and Comparison\n",
        "\n",
        "Train multiple algorithms and collect their predictions for comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create models dictionary with 9 algorithms:\n",
        "# - Logistic Regression, Decision Tree, Random Forest\n",
        "# - Gradient Boosting, XGBoost, LightGBM\n",
        "# - SVM, k-Nearest Neighbors, Naive Bayes\n",
        "# TODO: Print the number of models and their names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Loop through models and:\n",
        "# 1. Train on X_train_scaled, y_train\n",
        "# 2. Get predictions on X_test_scaled\n",
        "# 3. Get probability predictions (if available)\n",
        "# 4. Calculate: accuracy, precision, recall, f1_score, ROC-AUC\n",
        "# 5. Store results in dictionaries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 5: Model Evaluation and Visualization\n",
        "\n",
        "Analyze and visualize model performance using multiple metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create results DataFrame and sort by accuracy\n",
        "# TODO: Display formatted comparison table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create horizontal bar chart comparing model accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create grouped bar chart for multiple metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Plot ROC curves for all models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create confusion matrices for top 3 models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Print classification reports for top 3 models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflection Question 4:** Which model performed best? For medical diagnosis, which metric matters most and why?\n",
        "\n",
        "*Write your analysis here:*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 6: Cross-Validation Analysis\n",
        "\n",
        "Use cross-validation to get more robust performance estimates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Perform 5-fold stratified cross-validation for all models\n",
        "# TODO: Store mean, std, and test accuracy\n",
        "# TODO: Display CV results table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create error bar plot for CV results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflection Question 5:** How do CV results compare to test results? Which model shows most stability?\n",
        "\n",
        "*Write your analysis here:*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 7: Final Model Selection and Insights\n",
        "\n",
        "Synthesize all metrics to determine the best overall model and provide actionable insights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Combine all metrics and calculate overall ranking\n",
        "# TODO: Display comprehensive summary of top 3 models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Final Reflection:** Which model would you deploy and why? Consider performance, interpretability, and deployment constraints.\n",
        "\n",
        "*Write your decision and justification here:*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Key Insights and Recommendations\n",
        "\n",
        "### Algorithm Characteristics\n",
        "\n",
        "**Ensemble Methods** - Random Forest, XGBoost, LightGBM typically perform best due to handling non-linear relationships well.\n",
        "\n",
        "**Linear Models** - Logistic Regression provides interpretable baseline with fast training.\n",
        "\n",
        "**Kernel Methods** - SVM sensitive to scaling; computationally expensive for large datasets.\n",
        "\n",
        "**Instance-Based** - kNN depends heavily on parameter k and distance metric.\n",
        "\n",
        "### Recommendations by Use Case\n",
        "\n",
        "**Production Deployment:** Choose top ensemble method for best accuracy and robustness.\n",
        "\n",
        "**Interpretability:** Choose Logistic Regression or Decision Tree when transparency is critical.\n",
        "\n",
        "**Real-Time:** Choose LightGBM or Logistic Regression for fastest inference.\n",
        "\n",
        "**Medical Context:** Recall is crucial - minimize false negatives.\n",
        "\n",
        "---\n",
        "\n",
        "## Optional Challenges (Bonus)\n",
        "\n",
        "1. **Hyperparameter Tuning**: Use GridSearchCV to optimize your top model\n",
        "2. **Feature Selection**: Implement and compare performance with selected features  \n",
        "3. **Ensemble Creation**: Build voting/stacking classifier with top 3 models\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Submission Guidelines\n",
        "\n",
        "### Submission Requirements\n",
        "\n",
        "Before submitting your project, ensure you have:\n",
        "\n",
        "1. **Completed all TODO sections** with working code\n",
        "2. **Answered all reflection questions** with detailed analysis\n",
        "3. **Generated all required visualizations** \n",
        "4. **Tested code and verified** all outputs\n",
        "5. **Documented findings** and insights\n",
        "\n",
        "### How to Submit\n",
        "\n",
        "**Step 1:** Send LinkedIn connection request to: https://www.linkedin.com/in/hashirahmed07/\n",
        "\n",
        "**Step 2:** Clean up notebook and ensure all cells run without errors\n",
        "\n",
        "**Step 3:** Submit with title format: **30_Days_ML_Practice_Project_Week2**\n",
        "\n",
        "### Evaluation Criteria\n",
        "\n",
        "Your project will be evaluated based on:\n",
        "\n",
        "- **Code Quality (30%)** - Correctness, organization, readability\n",
        "- **Analysis Quality (30%)** - Depth of EDA and interpretation  \n",
        "- **Visualization (20%)** - Clarity and professionalism\n",
        "- **Insights (20%)** - Model comparison and justification\n",
        "\n",
        "---\n",
        "\n",
        "**Good luck with your project! Remember: The goal is to learn and practice, not just to get perfect results.**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
